---
---

@string{aps = {American Physical Society,}}

@inproceedings{jain2019performance,
  title={Performance characterization of dnn training using tensorflow and pytorch on modern clusters},
  author={Jain, Arpan and Awan, Ammar Ahmad and Anthony, Quentin and Subramoni, Hari and Panda, Dhableswar K DK},
  booktitle={2019 IEEE International Conference on Cluster Computing (CLUSTER)},
  pages={1--11},
  year={2019},
  organization={IEEE}
}

@INPROCEEDINGS {mcr_dl,
author = {Q. Anthony and A. Awan and J. Rasley and Y. He and A. Shafi and M. Abduljabbar and H. Subramoni and D. Panda},
booktitle = {2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
title = {MCR-DL: Mix-and-Match Communication Runtime for Deep Learning},
year = {2023},
volume = {},
issn = {},
pages = {996-1006},
keywords = {deep learning;training;runtime;tensors;computational modeling;parallel processing;system recovery},
doi = {10.1109/IPDPS54959.2023.00103},
url = {https://doi.ieeecomputersociety.org/10.1109/IPDPS54959.2023.00103},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may},
selected = {true}
}

@inproceedings{black-etal-2022-gpt,
    title = "{GPT}-{N}eo{X}-20{B}: An Open-Source Autoregressive Language Model",
    author = "Black, Sidney  and
      Biderman, Stella  and
      Hallahan, Eric  and
      Anthony, Quentin  and
      Gao, Leo  and
      Golding, Laurence  and
      He, Horace  and
      Leahy, Connor  and
      McDonell, Kyle  and
      Phang, Jason  and
      Pieler, Michael  and
      Prashanth, Usvsn Sai  and
      Purohit, Shivanshu  and
      Reynolds, Laria  and
      Tow, Jonathan  and
      Wang, Ben  and
      Weinbach, Samuel",
    booktitle = "Proceedings of BigScience Episode {\#}5 -- Workshop on Challenges {\&} Perspectives in Creating Large Language Models",
    month = may,
    year = "2022",
    address = "virtual+Dublin",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.bigscience-1.9",
    doi = "10.18653/v1/2022.bigscience-1.9",
    pages = "95--136",
    abstract = "We introduce GPT-NeoX-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license. It is, to the best of our knowledge, the largest dense autoregressive model that has publicly available weights at the time of submission. In this work, we describe GPT-NeoX-20B{'}s architecture and training, and evaluate its performance. We open-source the training and evaluation code, as well as the model weights, at https://github.com/EleutherAI/gpt-neox.",
}

@misc{peng2023rwkv,
      title={RWKV: Reinventing RNNs for the Transformer Era}, 
      author={Bo Peng and Eric Alcaide and Quentin Anthony and Alon Albalak and Samuel Arcadinho and Huanqi Cao and Xin Cheng and Michael Chung and Matteo Grella and Kranthi Kiran GV and Xuzheng He and Haowen Hou and Przemyslaw Kazienko and Jan Kocon and Jiaming Kong and Bartlomiej Koptyra and Hayden Lau and Krishna Sri Ipsit Mantri and Ferdinand Mom and Atsushi Saito and Xiangru Tang and Bolun Wang and Johan S. Wind and Stansilaw Wozniak and Ruichong Zhang and Zhenyuan Zhang and Qihang Zhao and Peng Zhou and Jian Zhu and Rui-Jie Zhu},
      year={2023},
      eprint={2305.13048},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{redscat_comp,
  author={Zhou, Qinghua and Anthony, Quentin and Xu, Lang and Shafi, Aamir and Abduljabbar, Mustafa and Subramoni, Hari and Panda, Dhabaleswar K. DK},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Accelerating Distributed Deep Learning Training with Compression Assisted Allgather and Reduce-Scatter Communication}, 
  year={2023},
  volume={},
  number={},
  pages={134-144},
  doi={10.1109/IPDPS54959.2023.00023}}

@misc{biderman2023pythia,
      title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling}, 
      author={Stella Biderman and Hailey Schoelkopf and Quentin Anthony and Herbie Bradley and Kyle O'Brien and Eric Hallahan and Mohammad Aflah Khan and Shivanshu Purohit and USVSN Sai Prashanth and Edward Raff and Aviya Skowron and Lintang Sutawika and Oskar van der Wal},
      year={2023},
      eprint={2304.01373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{biderman2023emergent,
      title={Emergent and Predictable Memorization in Large Language Models}, 
      author={Stella Biderman and USVSN Sai Prashanth and Lintang Sutawika and Hailey Schoelkopf and Quentin Anthony and Shivanshu Purohit and Edward Raff},
      year={2023},
      eprint={2304.11158},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{bcast_comp,
  author={Zhou, Qinghua and Anthony, Quentin and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K. DK},
  booktitle={2022 IEEE 29th International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={Accelerating Broadcast Communication with GPU Compression for Deep Learning Workloads}, 
  year={2022},
  volume={},
  number={},
  pages={22-31},
  doi={10.1109/HiPC56025.2022.00016}}


@INPROCEEDINGS{alltoall_chenchun,
  author={Chen, Chen-Chun and Khorassani, Kawthar Shafie and Anthony, Quentin G. and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Highly Efficient Alltoall and Alltoallv Communication Algorithms for GPU Systems}, 
  year={2022},
  volume={},
  number={},
  pages={24-33},
  doi={10.1109/IPDPSW55747.2022.00014}}


@INPROCEEDINGS{scamp,
  author={Anthony, Quentin and Xu, Lang and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K. Dk},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)}, 
  title={ScaMP: Scalable Meta-Parallelism for Deep Learning Search}, 
  year={2023},
  volume={},
  number={},
  pages={346-348},
  doi={10.1109/CCGridW59191.2023.00080}},
  selected = {true}

@inproceedings{awan2020hypar,
  title={HyPar-Flow: exploiting MPI and Keras for scalable hybrid-parallel DNN training with tensorflow},
  author={Awan, Ammar Ahmad and Jain, Arpan and Anthony, Quentin and Subramoni, Hari and Panda, Dhabaleswar K},
  booktitle={International Conference on High Performance Computing},
  pages={83--103},
  year={2020},
  organization={Springer, Cham}
}

@inproceedings{anthony2020efficient,
  title={Efficient training of semantic image segmentation on summit using horovod and mvapich2-gdr},
  author={Anthony, Quentin and Awan, Ammar Ahmad and Jain, Arpan and Subramoni, Hari and Panda, Dhabaleswar K DK},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  pages={1015--1023},
  year={2020},
  organization={IEEE},
  selected={true}
}

@inproceedings{jain2020gems,
  title={Gems: Gpu-enabled memory-aware model-parallelism system for distributed dnn training},
  author={Jain, Arpan and Awan, Ammar Ahmad and Aljuhani, Asmaa M and Hashmi, Jahanzeb Maqbool and Anthony, Quentin G and Subramoni, Hari and Panda, Dhableswar K and Machiraju, Raghu and Parwani, Anil},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2020},
  organization={IEEE}
}

@inproceedings{ghazimirsaeed2020accelerating,
  title={Accelerating GPU-based Machine Learning in Python using MPI Library: A Case Study with MVAPICH2-GDR},
  author={Ghazimirsaeed, S Mahdieh* and Anthony, Quentin* and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K DK},
  booktitle={2020 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC) and Workshop on Artificial Intelligence and Machine Learning for Scientific Applications (AI4S)},
  pages={1--12},
  year={2020},
  organization={IEEE},
  selected={true}
}

@inproceedings{anthony2021scaling,
  title={Scaling Single-Image Super-Resolution Training on Modern HPC Clusters: Early Experiences},
  author={Anthony, Quentin and Xu, Lang and Subramoni, Hari and Panda, Dhabaleswar K DK},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  pages={923--932},
  year={2021},
  organization={IEEE},
  selected={true}
}

@inproceedings{khorassani2021adaptive,
  title={Adaptive and Hierarchical Large Message All-to-all Communication Algorithms for Large-scale Dense GPU Systems},
  author={Khorassani, Kawthar Shafie and Chu, Ching-Hsiang and Anthony, Quentin G and Subramoni, Hari and Panda, Dhabaleswar K},
  booktitle={2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
  pages={113--122},
  year={2021},
  organization={IEEE}
}

@article{kousha2021cross,
  title={Cross-layer Visualization and Profiling of Network and I/O Communication for HPC Clusters},
  author={Kousha, Pouya and Anthony, Quentin and Subramoni, Hari and Panda, Dhabaleswar K},
  journal={arXiv preprint arXiv:2109.08329},
  year={2021}
}

@inproceedings{anthony2021evaluating,
  title={Evaluating Multi-Level Checkpointing for Distributed Deep Neural Network Training},
  author={Anthony, Quentin and Dai, Donglai},
  booktitle={SC Workshops Supplementary Proceedings (SCWS)},
  year={2021},
  selected={true}
}

@article{blackgpt,
  title={GPT-NeoX-20B: An Open-Source Autoregressive Language Model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others}
}
